{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day 1, Puzzle 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.loadtxt('day1/input')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(201.0, 1819.0)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Brute force\n",
    "pairs = [(a, b) for a in data for b in data if a + b == 2020 and a <= b]\n",
    "pair = pairs[0]\n",
    "pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "365619.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pair[0] * pair[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day 1, Puzzle 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(348.0, 701.0, 971.0)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Brute force\n",
    "trips = [(a, b, c) for a in data for b in data for c in data if a + b + c == 2020 \n",
    "         and a <= b <= c]\n",
    "trips = trips[0]\n",
    "trips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "236873508.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trips[0] * trips[1] * trips[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.16 s ± 25.8 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit trips = [(a, b, c) for a in data for b in data for c in data if a + b + c == 2020 and a <= b <= c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.4 s ± 21.7 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit trips = [(a, b, c) for a in data for b in data for c in data if a <= b <= c and a + b + c == 2020]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day 2, Puzzle 1\n",
    "\n",
    "Example password rule lines:\n",
    "\n",
    "```\n",
    "1-14 b: bbbbbbbbbbbbbbbbbbb\n",
    "3-14 v: vvpvvvmvvvvvvvv\n",
    "2-5 m: mfvxmmm\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pw = 'vvpvvvmvvvvvvvv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count occurences of some letter using built in method\n",
    "pw.count('v')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Need to get the lower and upper limits. Read the file line by line and regex it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "line = '1-14 b: bbbbbbbbbbbbbbbbbbb'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = '^(\\d+)-(\\d+)\\s+(\\w):\\s+(\\w+)$'\n",
    "rgx = re.match(pattern, line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<re.Match object; span=(0, 27), match='1-14 b: bbbbbbbbbbbbbbbbbbb'>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rgx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "lowerlim = int(rgx.group(1))\n",
    "uppererlim = int(rgx.group(2))\n",
    "charcount = rgx.group(4).count(rgx.group(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "charcount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "548\n"
     ]
    }
   ],
   "source": [
    "pattern = '^(\\d+)-(\\d+)\\s+(\\w):\\s+(\\w+)$'\n",
    "good_pw = 0\n",
    "with open('day2/input', 'r') as input:\n",
    "    for line in input:\n",
    "        line = line.rstrip()\n",
    "        rgx = re.match(pattern, line)\n",
    "        #print(line)\n",
    "        lowerlim = int(rgx.group(1))\n",
    "        upperlim = int(rgx.group(2))\n",
    "        charcount = rgx.group(4).count(rgx.group(3))\n",
    "        # print(lowerlim, charcount, upperlim)\n",
    "        if lowerlim <= charcount <= upperlim:\n",
    "            good_pw += 1\n",
    "\n",
    "print(good_pw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day 2, Puzzle 2\n",
    "\n",
    "Each policy actually describes two positions in the password, where 1 means the first character, 2 means the second character, and so on. (Be careful; Toboggan Corporate Policies have no concept of \"index zero\"!) Exactly one of these positions must contain the given letter. Other occurrences of the letter are irrelevant for the purposes of policy enforcement.\n",
    "\n",
    "Example password rule lines:\n",
    "\n",
    "```\n",
    "1-14 b: bbbbbbbbbbbbbbbbbbb\n",
    "3-14 v: vvpvvvmvvvvvvvv\n",
    "2-5 m: mfvxmmm\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "502\n"
     ]
    }
   ],
   "source": [
    "pattern = '^(\\d+)-(\\d+)\\s+(\\w):\\s+(\\w+)$'\n",
    "good_pw = 0\n",
    "with open('day2/input', 'r') as input:\n",
    "    for line in input:\n",
    "        line = line.rstrip()\n",
    "        rgx = re.match(pattern, line)\n",
    "        lowerlim = int(rgx.group(1))\n",
    "        upperlim = int(rgx.group(2))\n",
    "        pw = rgx.group(4)\n",
    "        ch = rgx.group(3)\n",
    "        \n",
    "        try:\n",
    "            if (pw[lowerlim-1] == ch) + (pw[upperlim-1] == ch) == 1:\n",
    "                good_pw += 1\n",
    "        except:\n",
    "            print(lowerlim, upperlim, pw, ch)\n",
    "            exit()\n",
    "\n",
    "print(good_pw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "True + False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day 3, Puzzle 1\n",
    "\n",
    "Ski down, right 3, down 1. Count number of trees hit. Field duplicates to the right indefinitely.\n",
    "\n",
    "\n",
    "```\n",
    ".........#..##.##..............\n",
    "#...#.#..#.....................\n",
    ".#...#..#...................#..\n",
    "........##..#...#..............\n",
    ".#.#.....#..#..##......#.......\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(323,)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "slope = np.genfromtxt('day3/input', delimiter=0, \n",
    "                      dtype='str',comments='X')\n",
    "slope.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['.........#..##.##..............',\n",
       "       '#...#.#..#.....................',\n",
       "       '.#...#..#...................#..',\n",
       "       '........##..#...#..............',\n",
       "       '.#.#.....#..#..##......#.......',\n",
       "       '....#..#...#..##........#..##..',\n",
       "       '...#....##........#.......#.#..',\n",
       "       '....#................#...###..#',\n",
       "       '...#...#.#..#....#.......####.#',\n",
       "       '.....#...#..........#...#..#.#.',\n",
       "       '....#..#............#.#.#.#..#.',\n",
       "       '..#....#.###..#............#...',\n",
       "       '.....#.............#.#.........',\n",
       "       '.#.##............##.........#..',\n",
       "       '...##...#..#....#.##..#.....#..',\n",
       "       '..............#.#.........#.##.',\n",
       "       '...........#.....##....##......',\n",
       "       '.......#............#...#......',\n",
       "       '............#.#....#....#..#..#',\n",
       "       '....#................####......',\n",
       "       '...#.........................##',\n",
       "       '..........#........#.#.........',\n",
       "       '....#.#....#...........#......#',\n",
       "       '..#.#..##......##..##..#..#.#..',\n",
       "       '...#.....##......#.#.#.........',\n",
       "       '.........#.#....#...#.#.#......',\n",
       "       '.......#.......###.#.......#...',\n",
       "       '..#............##..#.......#...',\n",
       "       '...#....#......#...#...#...#...',\n",
       "       '......#..#.#.....##......#.....',\n",
       "       '...........##...##...#....#.##.',\n",
       "       '#.##..#.....##..#.#............',\n",
       "       '.#.#.....##......#.##........#.',\n",
       "       '..#...#...#...#..........#...##',\n",
       "       '...##.........................#',\n",
       "       '.....#......#.....##....#.....#',\n",
       "       '..#........#...................',\n",
       "       '#......#..#.#..#..#.#..#...#...',\n",
       "       '...............#..........#....',\n",
       "       '.....#...........#......#....#.',\n",
       "       '........#..#...............#...',\n",
       "       '.........#...#.......#.#..#...#',\n",
       "       '..#..#......#.##..........#....',\n",
       "       '.#...#....#.....#.............#',\n",
       "       '.##.....#.........#......#..#..',\n",
       "       '........#..##.......#......#...',\n",
       "       '.......#.....###......#..#.....',\n",
       "       '.......#.#.......#.............',\n",
       "       '...#................##.#.......',\n",
       "       '..##..#...#.#...#.#..#.#.#.##..',\n",
       "       '.......#.#............#...#....',\n",
       "       '#...#.....#......#..........##.',\n",
       "       '.#.......#......#.......#.#.#..',\n",
       "       '.#.##.#.#...........#..........',\n",
       "       '.......#.....#....#.#.##......#',\n",
       "       '.###..#...#.............##.....',\n",
       "       '......#......#.................',\n",
       "       '##...#.#...##...#.#.....#....#.',\n",
       "       '#.............#....##...#....#.',\n",
       "       '#.#...#....#........#.###..##..',\n",
       "       '......#.........#......#.#.#.#.',\n",
       "       '..#.#.#.....#........#..#...#..',\n",
       "       '#.##....#.#......#...........#.',\n",
       "       '.#.#.####.........#..#.##....##',\n",
       "       '......##...............#......#',\n",
       "       '.......#.........#........#.#..',\n",
       "       '....#....#..#.##.........#..#..',\n",
       "       '.#..........#.##....#.#..#.....',\n",
       "       '#..#.#............#..#....#.#.#',\n",
       "       '..................#..#.........',\n",
       "       '##..##.#....#.................#',\n",
       "       '..................#........#..#',\n",
       "       '.....#.........#.......##......',\n",
       "       '.....................#.#..#...#',\n",
       "       '.....#.........#..........#.#..',\n",
       "       '...#.#..#..#.#.#.......#.......',\n",
       "       '.....#.....#.#.........#.....##',\n",
       "       '.............##....#....##.#...',\n",
       "       '.#......#........##..#...###...',\n",
       "       '........#.......##.##.#......#.',\n",
       "       '..#....................#.##..#.',\n",
       "       '......#.......#..#....##.#.....',\n",
       "       '...#....#.......##...#.......#.',\n",
       "       '.#.#..#.#..........##..........',\n",
       "       '....#.......##...........#.....',\n",
       "       '###....#.......#..#...#.....##.',\n",
       "       '...#......#.........#..#.#..#.#',\n",
       "       '#.........#..##.#..............',\n",
       "       '.#.....#..##.#..#..###.....##.#',\n",
       "       '..........#..#....##.......#...',\n",
       "       '.#..#.#...#...##.#..#.##.#.....',\n",
       "       '#....#...#........#......##....',\n",
       "       '..#.####....#.#........#....#..',\n",
       "       '#......#............#.#........',\n",
       "       '...#..#.......##...........#...',\n",
       "       '.........#..#.#..#.###.#...#..#',\n",
       "       '..#....##.......#.............#',\n",
       "       '............#..#......#........',\n",
       "       '........#......#..............#',\n",
       "       '..#.#.#...........#............',\n",
       "       '...........#......##.#.#.......',\n",
       "       '.#..........#...........#..#...',\n",
       "       '.....#...#..#.........##...#...',\n",
       "       '.......#....##....#.#.........#',\n",
       "       '..#.#......#.......#...##.#....',\n",
       "       '.....#..........#........#.....',\n",
       "       '#.......#.......#............#.',\n",
       "       '..##.#.....#.##.#.#.#..#.......',\n",
       "       '..#...#.......#.###............',\n",
       "       '.#...#..#....#...#...#..#....##',\n",
       "       '.....#.....#...................',\n",
       "       '.......................#......#',\n",
       "       '......#...##.........#...#..#..',\n",
       "       '.....#..#.....#..............#.',\n",
       "       '.#.##..#..#....................',\n",
       "       '....#..#...#....#.............#',\n",
       "       '..###..#...#......#.....#......',\n",
       "       '..#......###....#.....#.....###',\n",
       "       '...#.##..#...#.....#........#..',\n",
       "       '.#.#...........##....#...#.##..',\n",
       "       '.......#...##......#..#..#.....',\n",
       "       '#.............#..#...##.#..#..#',\n",
       "       '..........#......#.......#.....',\n",
       "       '...............#.#.#....#...#..',\n",
       "       '#.......#.#..#.....#........#..',\n",
       "       '.#.#.#.......#..#.........##...',\n",
       "       '......#.....#.#....#...........',\n",
       "       '..#.....##.#........##.#......#',\n",
       "       '...###...#..#.........#........',\n",
       "       '....#...................#..#...',\n",
       "       '.##........#...................',\n",
       "       '....#..#...........#.#.........',\n",
       "       '.....#.......#...#....#.#......',\n",
       "       '.........#...#.......#.#...#...',\n",
       "       '.......#.#..#....#....#.......#',\n",
       "       '..#.............#..............',\n",
       "       '.#...#..#.#.#..#............#..',\n",
       "       '...#.##.##..#..#...........##..',\n",
       "       '...........#...#..#.#........#.',\n",
       "       '....#...#.....#...#.#....#...#.',\n",
       "       '.......#.#...##..#.............',\n",
       "       '.......................#....#..',\n",
       "       '..#..#.....#...........#....#..',\n",
       "       '.#..#...#.##........##....#....',\n",
       "       '#.....##.#.#.......#.....#...#.',\n",
       "       '.#....#.......................#',\n",
       "       '#..##..###...#.........#.......',\n",
       "       '..##...#...#..........#....#...',\n",
       "       '......#..##......##.#.........#',\n",
       "       '................#........#..#..',\n",
       "       '.....#.#..#.....#.......#..#...',\n",
       "       '..#..#.....#.......#..#..#...#.',\n",
       "       '.#....#...#...#......##.....#..',\n",
       "       '....#........#...#......##....#',\n",
       "       '..#..........##......#......#..',\n",
       "       '#.#.....#.....#.......#........',\n",
       "       '...#...#......#....##.#..#...##',\n",
       "       '...#....#...#.#...........##...',\n",
       "       '#....##...#...#....#...........',\n",
       "       '...#.#..#...#..............##..',\n",
       "       '#..#..........##.#.#.....#.....',\n",
       "       '..#...#.........#.#..........#.',\n",
       "       '....#.....#..........#.........',\n",
       "       '........................#......',\n",
       "       '.#.....#.#...###...#....#......',\n",
       "       '....##....#....#..#.##........#',\n",
       "       '..#........#.........#.......#.',\n",
       "       '.....#.#......#...#...#........',\n",
       "       '........#..#.....#....###....#.',\n",
       "       '...........#..#.#....#.#....##.',\n",
       "       '.......#.....##.#............#.',\n",
       "       '...............#........##.##..',\n",
       "       '.............#...##......#...#.',\n",
       "       '#...##.#.......#......###.....#',\n",
       "       '..........#...#........#..#....',\n",
       "       '....#....................#...#.',\n",
       "       '.#......#...#.......#....#.#...',\n",
       "       '....#.......................#..',\n",
       "       '#...#...#...#.##....##.........',\n",
       "       '..........#.#...##.#...#.......',\n",
       "       '..#...............#....#..#...#',\n",
       "       '#..#..#...#..#.........#...#...',\n",
       "       '.....#..#..........#.##.#..##..',\n",
       "       '........#......##.....#........',\n",
       "       '.#....#.#.........#...#..#.#...',\n",
       "       '....#..............##..........',\n",
       "       '#...............#..............',\n",
       "       '..###.........#....##.........#',\n",
       "       '.........#.#....##........#...#',\n",
       "       '....#.#..#......#...#..........',\n",
       "       '...#.#.....#....#..#....#.#..#.',\n",
       "       '............#..#.....#...##....',\n",
       "       '...........#....#.#.#...#......',\n",
       "       '#...............#....###.......',\n",
       "       '.........#.....##.#..#..#......',\n",
       "       '...#...##...###...............#',\n",
       "       '.#......#.#.#.................#',\n",
       "       '.........##..#............#....',\n",
       "       '..#..#.....#.....#.#...........',\n",
       "       '.#......##............#.#....#.',\n",
       "       '.#.##..##.##..#.........#.....#',\n",
       "       '...##.##......##.##......#.....',\n",
       "       '##.....#.#...#...#...#..#......',\n",
       "       '....................#......#...',\n",
       "       '.....#.................#...###.',\n",
       "       '...........#..#.........#.#....',\n",
       "       '...#........#..#........#....#.',\n",
       "       '#................#......###...#',\n",
       "       '.............##.#.....#.#......',\n",
       "       '...#...#.##..#........##.......',\n",
       "       '#..#.##...#....#.#.............',\n",
       "       '.#.........#.#..#...........#..',\n",
       "       '....#...#.....#.#..........#...',\n",
       "       '.#.#....###.......##.....#.##..',\n",
       "       '.##....##......#......#.#....#.',\n",
       "       '..#...#.#........#...#..##.....',\n",
       "       '..............###..........##..',\n",
       "       '#....#..##.....#.....#.....#...',\n",
       "       '...#...#....................#..',\n",
       "       '.#....#.#.....#.#..#..##.......',\n",
       "       '#...##..###......#.............',\n",
       "       '..........#.#....##.#........##',\n",
       "       '..#..#.....#...#....#.#.#......',\n",
       "       '#.....#........#..##.#.........',\n",
       "       '....#.....#..........##......#.',\n",
       "       '......#..#.....#........#.....#',\n",
       "       '.....#..#....#...........#.##..',\n",
       "       '.#....................#....#..#',\n",
       "       '........#..#...........#.......',\n",
       "       '#....#.#.......#........#.#..#.',\n",
       "       '........#.....#...#............',\n",
       "       '..#........#........#....#...#.',\n",
       "       '.....##.......#..#..........#..',\n",
       "       '......#.#......###...#....##..#',\n",
       "       '.#..#.............#.#..........',\n",
       "       '#.....##.#.#.#.#.#.....#.....#.',\n",
       "       '.#..#.....#.......#.#.....#....',\n",
       "       '###....##...#.#...#..#......###',\n",
       "       '.#................#.....#.##...',\n",
       "       '....##....#.#........###.#.#...',\n",
       "       '#.#....#........#.....#.......#',\n",
       "       '..........#..........#.##...#..',\n",
       "       '....#....#..##......#..#.......',\n",
       "       '.....#..........#.##...........',\n",
       "       '##......#.#......#.##..........',\n",
       "       '##..........##.......##........',\n",
       "       '..#.....#....#.##..#..#..#.....',\n",
       "       '......###...#...........#...###',\n",
       "       '#..#.............##............',\n",
       "       '...#.###.....#..#.........#.#..',\n",
       "       '......#...............#...#.#..',\n",
       "       '.....#...##.#...#.....#.#..#...',\n",
       "       '..#..#.#....#.#................',\n",
       "       '...............##.....#........',\n",
       "       '......#.#.....#...#.........#..',\n",
       "       '........#..#...#.#...#......#..',\n",
       "       '#...........#.......#...##...#.',\n",
       "       '........#.#...#..##..#.#...#...',\n",
       "       '..#....#...#......#..........##',\n",
       "       '..#..............##...##.#.....',\n",
       "       '...#....#..#....##.........#.#.',\n",
       "       '.#.#....#..........#.......#...',\n",
       "       '...##....#.#....#....#.#...#...',\n",
       "       '..............#..##........#..#',\n",
       "       '..........#.#...##......#..#.#.',\n",
       "       '#...##..#......................',\n",
       "       '.......#........##.#.#.#.......',\n",
       "       '.........##..#.#.......####....',\n",
       "       '..#.............#..#........##.',\n",
       "       '##..#..#...#....#.....#...#..#.',\n",
       "       '..#.#...#.#.....#..............',\n",
       "       '..#....#....#..##...#.#........',\n",
       "       '##.....#..#...#................',\n",
       "       '#....#.....................#...',\n",
       "       '..............###.....#.#.#....',\n",
       "       '..#......##.#....#.#...##......',\n",
       "       '#...#.#......#...#.#......#....',\n",
       "       '....#...................##.#...',\n",
       "       '.........##......#.....#.####..',\n",
       "       '##..#........#.....#......##..#',\n",
       "       '...#..#...#...#.............#..',\n",
       "       '#..#..#.#......###...#.........',\n",
       "       '.......#.#..#........#....##..#',\n",
       "       '............#..##.....#.#.#....',\n",
       "       '#..#.....#.....#....##........#',\n",
       "       '......#..........##............',\n",
       "       '.....#...#...........#.........',\n",
       "       '...........#....#...#....#.#...',\n",
       "       '....#.........##.##.......#....',\n",
       "       '......#....#...........#.##...#',\n",
       "       '.##.#.#..##...#.....##.#...#...',\n",
       "       '.......#.#....#...#...#....#...',\n",
       "       '.#...##.#.#.....#..#....#......',\n",
       "       '.#....###..#.......#......#...#',\n",
       "       '..#.#.........#.........#.....#',\n",
       "       '.......#.#.##..#.#.......##..#.',\n",
       "       '.##............#.........#....#',\n",
       "       '.#...##.###..#........##.#..#..',\n",
       "       '..#........#.#.....##..##.#....',\n",
       "       '...........#...........#.....#.',\n",
       "       '.#...######..##...#.....#......',\n",
       "       '.#.##.#.......#......#......#..',\n",
       "       '.#.....#.....#........#........',\n",
       "       '...#..#...#.##...#...........#.',\n",
       "       '.......#.....#.......#.........',\n",
       "       '............#...###...........#',\n",
       "       '...#.......#.......##....#..#..',\n",
       "       '##.......#....#....####........',\n",
       "       '.......#.#......#..........#..#',\n",
       "       '#.....##..#..#.....#....#...#..',\n",
       "       '#............#........##.......',\n",
       "       '.#.#...#.............#..##.....',\n",
       "       '.#....#..#.#......#.##.......##',\n",
       "       '...................##...##..###',\n",
       "       '..#.....#...#................#.',\n",
       "       '..#...#....#...#.#.#...#.....#.',\n",
       "       '.....#............#....#...#..#',\n",
       "       '.#.....#....#..#......#.#.....#',\n",
       "       '............#.#.....####.##....',\n",
       "       '....#......###....#...#....#...',\n",
       "       '#.....#..#.....#..#...#.......#',\n",
       "       '..#.#...#....#....##..#...##...',\n",
       "       '.##..#..#..##....##...#........'], dtype='<U31')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "slope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "323"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(slope)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(slope[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "268\n"
     ]
    }
   ],
   "source": [
    "cur_row = 0\n",
    "cur_col = 0\n",
    "width = len(slope[0])\n",
    "num_trees = 0\n",
    "\n",
    "for i in range(len(slope) - 1):\n",
    "    cur_row += 1\n",
    "    cur_col = (cur_col + 3) % width\n",
    "    if slope[cur_row][cur_col] == '#':\n",
    "        num_trees += 1\n",
    "        \n",
    "print(num_trees)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day 3, Puzzle 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3093068400\n"
     ]
    }
   ],
   "source": [
    "paths = [(1, 1), (3, 1), (5, 1), (7, 1), (1, 2)]\n",
    "width = len(slope[0])\n",
    "length = len(slope)\n",
    "tree_counts = []\n",
    "    \n",
    "for path in paths:\n",
    "    cur_row = 0\n",
    "    cur_col = 0\n",
    "    num_trees = 0\n",
    "    for i in range(len(slope) - 1):\n",
    "        cur_row += path[1]\n",
    "        if cur_row > length:\n",
    "            break\n",
    "        cur_col = (cur_col + path[0]) % width\n",
    "        if slope[cur_row][cur_col] == '#':\n",
    "            num_trees += 1\n",
    "    tree_counts.append(num_trees)    \n",
    "\n",
    "total_trees = np.product(tree_counts)\n",
    "\n",
    "print(total_trees)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day 4, Puzzle 1\n",
    "passports\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You arrive at the airport only to realize that you grabbed your North Pole Credentials instead of your passport. While these documents are extremely similar, North Pole Credentials aren't issued by a country and therefore aren't actually valid documentation for travel in most of the world.\n",
    "\n",
    "It seems like you're not the only one having problems, though; a very long line has formed for the automatic passport scanners, and the delay could upset your travel itinerary.\n",
    "\n",
    "Due to some questionable network security, you realize you might be able to solve both of these problems at the same time.\n",
    "\n",
    "The automatic passport scanners are slow because they're having trouble detecting which passports have all required fields. The expected fields are as follows:\n",
    "\n",
    "    byr (Birth Year)\n",
    "    iyr (Issue Year)\n",
    "    eyr (Expiration Year)\n",
    "    hgt (Height)\n",
    "    hcl (Hair Color)\n",
    "    ecl (Eye Color)\n",
    "    pid (Passport ID)\n",
    "    cid (Country ID)\n",
    "\n",
    "Passport data is validated in batch files (your puzzle input). Each passport is represented as a sequence of key:value pairs separated by spaces or newlines. Passports are separated by blank lines.\n",
    "\n",
    "Here is an example batch file containing four passports:\n",
    "```\n",
    "ecl:gry pid:860033327 eyr:2020 hcl:#fffffd\n",
    "byr:1937 iyr:2017 cid:147 hgt:183cm\n",
    "\n",
    "iyr:2013 ecl:amb cid:350 eyr:2023 pid:028048884\n",
    "hcl:#cfa07d byr:1929\n",
    "\n",
    "hcl:#ae17e1 iyr:2013\n",
    "eyr:2024\n",
    "ecl:brn pid:760753108 byr:1931\n",
    "hgt:179cm\n",
    "\n",
    "hcl:#cfa07d eyr:2025 pid:166559648\n",
    "iyr:2011 ecl:brn hgt:59in\n",
    "```\n",
    "The first passport is valid - all eight fields are present. The second passport is invalid - it is missing hgt (the Height field).\n",
    "\n",
    "The third passport is interesting; the only missing field is cid, so it looks like data from North Pole Credentials, not a passport at all! Surely, nobody would mind if you made the system temporarily ignore missing cid fields. Treat this \"passport\" as valid.\n",
    "\n",
    "The fourth passport is missing two fields, cid and byr. Missing cid is fine, but missing any other field is not, so this passport is invalid.\n",
    "\n",
    "According to the above rules, your improved system would report 2 valid passports.\n",
    "\n",
    "Count the number of valid passports - those that have all required fields. Treat cid as optional. In your batch file, how many passports are valid?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "allkeys =  ['byr', 'iyr', 'eyr', 'hgt', 'hcl', 'ecl', 'pid', 'cid']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "testdict1 = {'ecl':'gry', \n",
    "            'pid':860033327, \n",
    "            'eyr':2020, \n",
    "            'hcl':'#fffffd', \n",
    "            'byr':1937, \n",
    "            'iyr':2017, \n",
    "            'cid':147, \n",
    "            'hgt':'183cm'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find missing keys in test data but not worrying if 'cid' is missing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_keys = {key for key in allkeys if key not in testdict1.keys() if key != 'cid'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set()"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'pid', 'hgt'}\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "testdict2 = {'ecl':'gry',  \n",
    "            'eyr':2020, \n",
    "            'hcl':'#fffffd', \n",
    "            'byr':1937, \n",
    "            'iyr':2017, \n",
    "            'cid':147, \n",
    "            }\n",
    "\n",
    "missing_keys = {key for key in allkeys if key not in testdict2.keys() if key != 'cid'}\n",
    "print(missing_keys)\n",
    "print(len(missing_keys))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set()"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testdict3 = {'ecl':'gry', \n",
    "            'pid':860033327, \n",
    "            'eyr':2020, \n",
    "            'hcl':'#fffffd', \n",
    "            'byr':1937, \n",
    "            'iyr':2017, \n",
    "            'hgt':'183cm'}\n",
    "\n",
    "missing_keys = {key for key in allkeys if key not in testdict3.keys() if key != 'cid'}\n",
    "missing_keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 good\n",
      "2 bad\n",
      "3 bad\n",
      "4 good\n",
      "5 bad\n",
      "6 bad\n",
      "7 good\n",
      "8 good\n",
      "9 good\n",
      "10 bad\n",
      "11 good\n",
      "12 good\n",
      "13 good\n",
      "14 good\n",
      "15 bad\n",
      "16 good\n",
      "17 bad\n",
      "18 good\n",
      "19 good\n",
      "20 good\n",
      "21 good\n",
      "22 good\n",
      "23 good\n",
      "24 good\n",
      "25 good\n",
      "26 good\n",
      "27 bad\n",
      "28 good\n",
      "29 good\n",
      "30 good\n",
      "31 good\n",
      "32 good\n",
      "33 bad\n",
      "34 bad\n",
      "35 good\n",
      "36 good\n",
      "37 good\n",
      "38 good\n",
      "39 good\n",
      "40 bad\n",
      "41 good\n",
      "42 bad\n",
      "43 good\n",
      "44 good\n",
      "45 bad\n",
      "46 good\n",
      "47 good\n",
      "48 good\n",
      "49 good\n",
      "50 bad\n",
      "51 good\n",
      "52 good\n",
      "53 good\n",
      "54 good\n",
      "55 good\n",
      "56 good\n",
      "57 good\n",
      "58 good\n",
      "59 good\n",
      "60 good\n",
      "61 bad\n",
      "62 bad\n",
      "63 good\n",
      "64 good\n",
      "65 good\n",
      "66 bad\n",
      "67 good\n",
      "68 good\n",
      "69 good\n",
      "70 good\n",
      "71 good\n",
      "72 good\n",
      "73 bad\n",
      "74 good\n",
      "75 good\n",
      "76 good\n",
      "77 good\n",
      "78 good\n",
      "79 good\n",
      "80 good\n",
      "81 good\n",
      "82 good\n",
      "83 bad\n",
      "84 good\n",
      "85 good\n",
      "86 good\n",
      "87 bad\n",
      "88 bad\n",
      "89 good\n",
      "90 good\n",
      "91 bad\n",
      "92 bad\n",
      "93 bad\n",
      "94 good\n",
      "95 good\n",
      "96 good\n",
      "97 good\n",
      "98 good\n",
      "99 good\n",
      "100 good\n",
      "101 good\n",
      "102 good\n",
      "103 good\n",
      "104 good\n",
      "105 good\n",
      "106 good\n",
      "107 good\n",
      "108 good\n",
      "109 good\n",
      "110 good\n",
      "111 good\n",
      "112 good\n",
      "113 bad\n",
      "114 good\n",
      "115 good\n",
      "116 bad\n",
      "117 good\n",
      "118 good\n",
      "119 good\n",
      "120 good\n",
      "121 good\n",
      "122 good\n",
      "123 good\n",
      "124 bad\n",
      "125 bad\n",
      "126 good\n",
      "127 good\n",
      "128 bad\n",
      "129 good\n",
      "130 good\n",
      "131 good\n",
      "132 good\n",
      "133 good\n",
      "134 bad\n",
      "135 good\n",
      "136 good\n",
      "137 good\n",
      "138 good\n",
      "139 good\n",
      "140 good\n",
      "141 good\n",
      "142 bad\n",
      "143 good\n",
      "144 bad\n",
      "145 bad\n",
      "146 good\n",
      "147 bad\n",
      "148 good\n",
      "149 bad\n",
      "150 good\n",
      "151 good\n",
      "152 bad\n",
      "153 bad\n",
      "154 good\n",
      "155 good\n",
      "156 good\n",
      "157 good\n",
      "158 good\n",
      "159 good\n",
      "160 good\n",
      "161 good\n",
      "162 good\n",
      "163 good\n",
      "164 good\n",
      "165 good\n",
      "166 bad\n",
      "167 bad\n",
      "168 good\n",
      "169 good\n",
      "170 good\n",
      "171 good\n",
      "172 good\n",
      "173 good\n",
      "174 bad\n",
      "175 good\n",
      "176 good\n",
      "177 good\n",
      "178 good\n",
      "179 bad\n",
      "180 good\n",
      "181 good\n",
      "182 good\n",
      "183 good\n",
      "184 good\n",
      "185 good\n",
      "186 bad\n",
      "187 good\n",
      "188 good\n",
      "189 good\n",
      "190 bad\n",
      "191 bad\n",
      "192 good\n",
      "193 good\n",
      "194 good\n",
      "195 bad\n",
      "196 good\n",
      "197 bad\n",
      "198 good\n",
      "199 bad\n",
      "200 bad\n",
      "201 good\n",
      "202 good\n",
      "203 good\n",
      "204 good\n",
      "205 good\n",
      "206 good\n",
      "207 bad\n",
      "208 bad\n",
      "209 bad\n",
      "210 good\n",
      "211 good\n",
      "212 good\n",
      "213 good\n",
      "214 good\n",
      "215 good\n",
      "216 good\n",
      "217 good\n",
      "218 bad\n",
      "219 good\n",
      "220 good\n",
      "221 good\n",
      "222 good\n",
      "223 good\n",
      "224 good\n",
      "225 good\n",
      "226 good\n",
      "227 bad\n",
      "228 good\n",
      "229 good\n",
      "230 good\n",
      "231 bad\n",
      "232 good\n",
      "233 good\n",
      "234 good\n",
      "235 bad\n",
      "236 good\n",
      "237 bad\n",
      "238 bad\n",
      "239 good\n",
      "240 good\n",
      "241 good\n",
      "242 good\n",
      "243 good\n",
      "244 good\n",
      "245 bad\n",
      "246 bad\n",
      "247 bad\n",
      "248 good\n",
      "249 good\n",
      "250 good\n",
      "251 good\n",
      "252 good\n",
      "253 good\n",
      "254 good\n",
      "255 bad\n",
      "256 bad\n",
      "257 bad\n",
      "258 good\n",
      "258 good\n",
      "196\n"
     ]
    }
   ],
   "source": [
    "#pattern = '(\\w+:[\\w#]+\\s*)+'\n",
    "allkeys =  ['byr', 'iyr', 'eyr', 'hgt', 'hcl', 'ecl', 'pid', 'cid']\n",
    "good_passport = 0\n",
    "entries = []\n",
    "new_dict = {}\n",
    "linenum = 0\n",
    "with open('day4/input', 'r') as input:\n",
    "    for line in input:\n",
    "        \n",
    "        line = line.rstrip()\n",
    "        if len(line) > 0:\n",
    "        # print(line)\n",
    "        # let's try non-regex approach\n",
    "        # rgx = re.match(pattern, line)\n",
    "        # print(rgx.groups())\n",
    "            new_entries = line.split()\n",
    "        #print(new_entries)\n",
    "        \n",
    "            entries.extend(new_entries)\n",
    "        else:\n",
    "            # Read a blank line, done with this chunk\n",
    "            # print(entries)\n",
    "            linenum += 1\n",
    "            for e in entries:\n",
    "                # Split each entry on the ':' and create the dictionary to test\n",
    "                key, val = e.split(':')\n",
    "                new_dict[key] = val\n",
    "            \n",
    "            # Look for missing keys other than 'cid'\n",
    "            missing_keys = {key for key in allkeys if key not in new_dict.keys() if key != 'cid' }\n",
    "            #print(missing_keys)\n",
    "            if len(missing_keys) > 0:\n",
    "                print(linenum, \"bad\")\n",
    "                #print(missing_keys)\n",
    "            else:\n",
    "                print(linenum, \"good\")\n",
    "                good_passport += 1\n",
    "                \n",
    "            entries = []\n",
    "            new_dict = {}\n",
    "\n",
    "# Deal with the last chunk of data (since no blank line at end)\n",
    "for e in entries:\n",
    "                \n",
    "    key, val = e.split(':')\n",
    "    new_dict[key] = val\n",
    "            \n",
    "missing_keys = {key for key in allkeys if key not in new_dict.keys() if key != 'cid' }\n",
    "#print(missing_keys)\n",
    "if len(missing_keys) > 0:\n",
    "    print(linenum, \"bad\")\n",
    "    #print(missing_keys)\n",
    "else:\n",
    "    print(linenum, \"good\")\n",
    "    good_passport += 1\n",
    "print(good_passport)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "entries = ['hcl:#6b5442', 'ecl:brn', 'iyr:2019', 'pid:637485594', 'hgt:171cm', 'eyr:2021', 'byr:1986']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hcl #6b5442\n",
      "ecl brn\n",
      "iyr 2019\n",
      "pid 637485594\n",
      "hgt 171cm\n",
      "eyr 2021\n",
      "byr 1986\n"
     ]
    }
   ],
   "source": [
    "for e in entries:\n",
    "    key, val = e.split(':')\n",
    "    print (key, val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hcl', '#6b5442']"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'hcl:#6b5442'.split(':')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(entries):\n",
    "    hgt_rgx = re.compile('([0-9]+)(in|cm)')\n",
    "    hcl_rgx = re.compile('#[0-9a-f]{6,6}')\n",
    "    pid_rgx = re.compile('[0-9]{9,9}')\n",
    "    for e in entries:\n",
    "        key, val = e.split(':')\n",
    "        \n",
    "        if key == 'byr':\n",
    "            assert 1920 <= float(val) <= 2002 \n",
    "        elif key == 'iyr':\n",
    "            assert 2010 <= float(val) <= 2020\n",
    "        elif key == 'eyr':\n",
    "            assert 2020 <= float(val) <= 2030\n",
    "        elif key == 'hgt':\n",
    "            hgt_match = re.match(hgt_rgx, val)\n",
    "            if hgt_match:\n",
    "                height = hgt_match.group(1)\n",
    "                units = hgt_match.group(2)\n",
    "                if units == 'cm':\n",
    "                    assert 150 <= float(height) <= 193\n",
    "                elif units == 'in':\n",
    "                    assert 59 <= float(height) <= 76\n",
    "                else:\n",
    "                    assert False\n",
    "            else:\n",
    "                assert False\n",
    "        elif key == 'hcl':\n",
    "            if not re.match(hcl_rgx, val):\n",
    "                assert False\n",
    "        elif key == 'ecl':\n",
    "            assert val in ['amb', 'blu', 'brn', 'gry', 'grn', 'hzl', 'oth']\n",
    "                \n",
    "        elif key == 'pid':\n",
    "            if not re.match(pid_rgx, val):\n",
    "                assert False    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'a' in ['amb', 'blu', 'brn', 'gry', 'grn', 'hzl', 'oth']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-56-a95be1593f83>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mvalidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mentries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-55-f8824923153c>\u001b[0m in \u001b[0;36mvalidate\u001b[0;34m(entries)\u001b[0m\n\u001b[1;32m     12\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;36m2010\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m2020\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'eyr'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m             \u001b[0;32massert\u001b[0m \u001b[0;36m2020\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m2030\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'hgt'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m             \u001b[0mhgt_match\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhgt_rgx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "validate(entries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val =1990\n",
    "1920 <= int(val) <= 2002 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 good\n",
      "2 bad\n",
      "3 bad\n",
      "4 bad\n",
      "5 bad\n",
      "6 bad\n",
      "7 bad\n",
      "8 bad\n",
      "9 bad\n",
      "10 bad\n",
      "11 good\n",
      "12 good\n",
      "13 good\n",
      "14 bad\n",
      "15 bad\n",
      "16 bad\n",
      "17 bad\n",
      "18 good\n",
      "19 good\n",
      "20 good\n",
      "21 good\n",
      "22 good\n",
      "23 bad\n",
      "24 bad\n",
      "25 good\n",
      "26 good\n",
      "27 bad\n",
      "28 good\n",
      "29 good\n",
      "30 good\n",
      "31 good\n",
      "32 good\n",
      "33 bad\n",
      "34 bad\n",
      "35 bad\n",
      "36 bad\n",
      "37 good\n",
      "38 good\n",
      "39 good\n",
      "40 bad\n",
      "41 good\n",
      "42 bad\n",
      "43 bad\n",
      "44 bad\n",
      "45 bad\n",
      "46 good\n",
      "47 good\n",
      "48 good\n",
      "49 bad\n",
      "50 bad\n",
      "51 bad\n",
      "52 bad\n",
      "53 good\n",
      "54 bad\n",
      "55 good\n",
      "56 good\n",
      "57 good\n",
      "58 bad\n",
      "59 good\n",
      "60 bad\n",
      "61 bad\n",
      "62 bad\n",
      "63 good\n",
      "64 bad\n",
      "65 good\n",
      "66 bad\n",
      "67 bad\n",
      "68 good\n",
      "69 good\n",
      "70 good\n",
      "71 good\n",
      "72 good\n",
      "73 bad\n",
      "74 good\n",
      "75 good\n",
      "76 good\n",
      "77 good\n",
      "78 bad\n",
      "79 good\n",
      "80 bad\n",
      "81 bad\n",
      "82 good\n",
      "83 bad\n",
      "84 good\n",
      "85 good\n",
      "86 good\n",
      "87 bad\n",
      "88 bad\n",
      "89 good\n",
      "90 bad\n",
      "91 bad\n",
      "92 bad\n",
      "93 bad\n",
      "94 bad\n",
      "95 good\n",
      "96 bad\n",
      "97 good\n",
      "98 good\n",
      "99 good\n",
      "100 good\n",
      "101 good\n",
      "102 bad\n",
      "103 good\n",
      "104 bad\n",
      "105 good\n",
      "106 good\n",
      "107 bad\n",
      "108 bad\n",
      "109 good\n",
      "110 good\n",
      "111 good\n",
      "112 bad\n",
      "113 bad\n",
      "114 good\n",
      "115 good\n",
      "116 bad\n",
      "117 good\n",
      "118 bad\n",
      "119 good\n",
      "120 good\n",
      "121 bad\n",
      "122 bad\n",
      "123 good\n",
      "124 bad\n",
      "125 bad\n",
      "126 good\n",
      "127 good\n",
      "128 bad\n",
      "129 good\n",
      "130 bad\n",
      "131 good\n",
      "132 bad\n",
      "133 good\n",
      "134 bad\n",
      "135 bad\n",
      "136 bad\n",
      "137 good\n",
      "138 bad\n",
      "139 bad\n",
      "140 bad\n",
      "141 good\n",
      "142 bad\n",
      "143 good\n",
      "144 bad\n",
      "145 bad\n",
      "146 good\n",
      "147 bad\n",
      "148 bad\n",
      "149 bad\n",
      "150 good\n",
      "151 good\n",
      "152 bad\n",
      "153 bad\n",
      "154 bad\n",
      "155 bad\n",
      "156 good\n",
      "157 bad\n",
      "158 bad\n",
      "159 bad\n",
      "160 bad\n",
      "161 bad\n",
      "162 bad\n",
      "163 good\n",
      "164 bad\n",
      "165 good\n",
      "166 bad\n",
      "167 bad\n",
      "168 good\n",
      "169 good\n",
      "170 bad\n",
      "171 good\n",
      "172 bad\n",
      "173 good\n",
      "174 bad\n",
      "175 good\n",
      "176 good\n",
      "177 bad\n",
      "178 good\n",
      "179 bad\n",
      "180 good\n",
      "181 good\n",
      "182 good\n",
      "183 bad\n",
      "184 good\n",
      "185 bad\n",
      "186 bad\n",
      "187 bad\n",
      "188 good\n",
      "189 bad\n",
      "190 bad\n",
      "191 bad\n",
      "192 good\n",
      "193 bad\n",
      "194 good\n",
      "195 bad\n",
      "196 good\n",
      "197 bad\n",
      "198 good\n",
      "199 bad\n",
      "200 bad\n",
      "201 bad\n",
      "202 good\n",
      "203 bad\n",
      "204 bad\n",
      "205 bad\n",
      "206 bad\n",
      "207 bad\n",
      "208 bad\n",
      "209 bad\n",
      "210 good\n",
      "211 good\n",
      "212 good\n",
      "213 bad\n",
      "214 bad\n",
      "215 bad\n",
      "216 bad\n",
      "217 good\n",
      "218 bad\n",
      "219 bad\n",
      "220 good\n",
      "221 good\n",
      "222 good\n",
      "223 bad\n",
      "224 good\n",
      "225 good\n",
      "226 bad\n",
      "227 bad\n",
      "228 bad\n",
      "229 bad\n",
      "230 good\n",
      "231 bad\n",
      "232 good\n",
      "233 bad\n",
      "234 bad\n",
      "235 bad\n",
      "236 bad\n",
      "237 bad\n",
      "238 bad\n",
      "239 bad\n",
      "240 good\n",
      "241 good\n",
      "242 good\n",
      "243 good\n",
      "244 bad\n",
      "245 bad\n",
      "246 bad\n",
      "247 bad\n",
      "248 good\n",
      "249 good\n",
      "250 good\n",
      "251 good\n",
      "252 good\n",
      "253 bad\n",
      "254 good\n",
      "255 bad\n",
      "256 bad\n",
      "257 bad\n",
      "258 bad\n",
      "258 bad\n",
      "115\n"
     ]
    }
   ],
   "source": [
    "#pattern = '(\\w+:[\\w#]+\\s*)+'\n",
    "allkeys =  ['byr', 'iyr', 'eyr', 'hgt', 'hcl', 'ecl', 'pid', 'cid']\n",
    "good_passport = 0\n",
    "entries = []\n",
    "new_dict = {}\n",
    "linenum = 0\n",
    "with open('day4/input', 'r') as input:\n",
    "    for line in input:\n",
    "        \n",
    "        line = line.rstrip()\n",
    "        if len(line) > 0:\n",
    "            new_entries = line.split()       \n",
    "            entries.extend(new_entries)\n",
    "        else:\n",
    "            # Read a blank line, done with this chunk\n",
    "            linenum += 1\n",
    "            for e in entries:\n",
    "                # Split each entry on the ':' and create the dictionary to test\n",
    "                pair = e.split(':')\n",
    "                key = pair[0]\n",
    "                val = pair[1]\n",
    "                new_dict[key] = val\n",
    "            \n",
    "            # Look for missing keys other than 'cid'\n",
    "            missing_keys = {key for key in allkeys if key not in new_dict.keys() if key != 'cid' }\n",
    "            #print(missing_keys)\n",
    "            if len(missing_keys) > 0:\n",
    "                print(linenum, \"bad\")\n",
    "                #print(missing_keys)\n",
    "            else:\n",
    "                try:\n",
    "                    validate(entries)\n",
    "                    print(linenum, \"good\")\n",
    "                    good_passport += 1\n",
    "                except AssertionError:\n",
    "                    print(linenum, \"bad\")\n",
    "                \n",
    "            entries = []\n",
    "            new_dict = {}\n",
    "\n",
    "# Deal with the last chunk of data (since no blank line at end)\n",
    "for e in entries:\n",
    "                \n",
    "    pair = e.split(':')\n",
    "    key = pair[0]\n",
    "    val = pair[1]\n",
    "    new_dict[key] = val\n",
    "            \n",
    "missing_keys = {key for key in allkeys if key not in new_dict.keys() if key != 'cid' }\n",
    "#print(missing_keys)\n",
    "if len(missing_keys) > 0:\n",
    "    print(linenum, \"bad\")\n",
    "    #print(missing_keys)\n",
    "else:\n",
    "                try:\n",
    "                    validate(entries)\n",
    "                    print(linenum, \"good\")\n",
    "                    good_passport += 1\n",
    "                except AssertionError:\n",
    "                    print(linenum, \"bad\")\n",
    "\n",
    "print(good_passport)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
